{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Modeling with RNN\n",
    "\n",
    "## Language Modeling predicts the next word in a sequence, which is crucial for tasks like text generation.\n",
    "\n",
    "### Steps:\n",
    "\n",
    "- Data Preparation: Prepare a text corpus (e.g., Shakespeare's works).\n",
    "- Preprocessing: Create sequences of text, tokenize, and prepare input-output pairs.\n",
    "- Model: Build an RNN model to predict the next word in a sequence.\n",
    "- Training: Train the model on the text corpus.\n",
    "- Generation: Generate new text by sampling from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example text data (replace with your text corpus)\n",
    "text = \"Your large text corpus here. It can be multiple sentences.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input sequences\n",
    "input_sequences = []\n",
    "for line in text.split('.'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences and create predictors and labels\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to be 3D (batch_size, timesteps, input_dim)\n",
    "X = np.expand_dims(X, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RNN model\n",
    "model = Sequential([\n",
    "    Embedding(total_words, 50, input_length=max_sequence_len-1),\n",
    "    LSTM(100),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model compilation\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 - 2s - 2s/step - accuracy: 0.0000e+00 - loss: 2.3991\n",
      "Epoch 2/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 2.3929\n",
      "Epoch 3/100\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.3750 - loss: 2.3867\n",
      "Epoch 4/100\n",
      "1/1 - 0s - 26ms/step - accuracy: 0.3750 - loss: 2.3805\n",
      "Epoch 5/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.3742\n",
      "Epoch 6/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.3677\n",
      "Epoch 7/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.3750 - loss: 2.3610\n",
      "Epoch 8/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.3539\n",
      "Epoch 9/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.3750 - loss: 2.3466\n",
      "Epoch 10/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.3387\n",
      "Epoch 11/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.3750 - loss: 2.3304\n",
      "Epoch 12/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.3214\n",
      "Epoch 13/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.3118\n",
      "Epoch 14/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.3750 - loss: 2.3014\n",
      "Epoch 15/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.2901\n",
      "Epoch 16/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 2.2778\n",
      "Epoch 17/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 2.2643\n",
      "Epoch 18/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 2.2497\n",
      "Epoch 19/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.2500 - loss: 2.2336\n",
      "Epoch 20/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.2500 - loss: 2.2160\n",
      "Epoch 21/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 2.1967\n",
      "Epoch 22/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.2500 - loss: 2.1756\n",
      "Epoch 23/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 2.1524\n",
      "Epoch 24/100\n",
      "1/1 - 0s - 25ms/step - accuracy: 0.2500 - loss: 2.1270\n",
      "Epoch 25/100\n",
      "1/1 - 0s - 20ms/step - accuracy: 0.2500 - loss: 2.0993\n",
      "Epoch 26/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.2500 - loss: 2.0692\n",
      "Epoch 27/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.2500 - loss: 2.0366\n",
      "Epoch 28/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 2.0016\n",
      "Epoch 29/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.2500 - loss: 1.9644\n",
      "Epoch 30/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.3750 - loss: 1.9252\n",
      "Epoch 31/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 1.8846\n",
      "Epoch 32/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.3750 - loss: 1.8428\n",
      "Epoch 33/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 1.8001\n",
      "Epoch 34/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.3750 - loss: 1.7565\n",
      "Epoch 35/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.3750 - loss: 1.7114\n",
      "Epoch 36/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.3750 - loss: 1.6642\n",
      "Epoch 37/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.3750 - loss: 1.6142\n",
      "Epoch 38/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.3750 - loss: 1.5612\n",
      "Epoch 39/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 0.5000 - loss: 1.5051\n",
      "Epoch 40/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.5000 - loss: 1.4465\n",
      "Epoch 41/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.6250 - loss: 1.3863\n",
      "Epoch 42/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 0.6250 - loss: 1.3255\n",
      "Epoch 43/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 0.8750 - loss: 1.2649\n",
      "Epoch 44/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 1.2052\n",
      "Epoch 45/100\n",
      "1/1 - 0s - 27ms/step - accuracy: 1.0000 - loss: 1.1464\n",
      "Epoch 46/100\n",
      "1/1 - 0s - 21ms/step - accuracy: 1.0000 - loss: 1.0884\n",
      "Epoch 47/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 1.0307\n",
      "Epoch 48/100\n",
      "1/1 - 0s - 20ms/step - accuracy: 1.0000 - loss: 0.9730\n",
      "Epoch 49/100\n",
      "1/1 - 0s - 19ms/step - accuracy: 1.0000 - loss: 0.9154\n",
      "Epoch 50/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.8584\n",
      "Epoch 51/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.8027\n",
      "Epoch 52/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.7491\n",
      "Epoch 53/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.6978\n",
      "Epoch 54/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.6490\n",
      "Epoch 55/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.6028\n",
      "Epoch 56/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.5595\n",
      "Epoch 57/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.5193\n",
      "Epoch 58/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.4820\n",
      "Epoch 59/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.4470\n",
      "Epoch 60/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.4141\n",
      "Epoch 61/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.3838\n",
      "Epoch 62/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.3566\n",
      "Epoch 63/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.3323\n",
      "Epoch 64/100\n",
      "1/1 - 0s - 30ms/step - accuracy: 1.0000 - loss: 0.3102\n",
      "Epoch 65/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.2896\n",
      "Epoch 66/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.2707\n",
      "Epoch 67/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.2536\n",
      "Epoch 68/100\n",
      "1/1 - 0s - 19ms/step - accuracy: 1.0000 - loss: 0.2379\n",
      "Epoch 69/100\n",
      "1/1 - 0s - 20ms/step - accuracy: 1.0000 - loss: 0.2231\n",
      "Epoch 70/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.2093\n",
      "Epoch 71/100\n",
      "1/1 - 0s - 19ms/step - accuracy: 1.0000 - loss: 0.1966\n",
      "Epoch 72/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.1851\n",
      "Epoch 73/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.1745\n",
      "Epoch 74/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.1645\n",
      "Epoch 75/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1552\n",
      "Epoch 76/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.1466\n",
      "Epoch 77/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1386\n",
      "Epoch 78/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1312\n",
      "Epoch 79/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1242\n",
      "Epoch 80/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1177\n",
      "Epoch 81/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1119\n",
      "Epoch 82/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.1064\n",
      "Epoch 83/100\n",
      "1/1 - 0s - 24ms/step - accuracy: 1.0000 - loss: 0.1013\n",
      "Epoch 84/100\n",
      "1/1 - 0s - 23ms/step - accuracy: 1.0000 - loss: 0.0965\n",
      "Epoch 85/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.0919\n",
      "Epoch 86/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.0876\n",
      "Epoch 87/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.0835\n",
      "Epoch 88/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.0795\n",
      "Epoch 89/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.0759\n",
      "Epoch 90/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.0724\n",
      "Epoch 91/100\n",
      "1/1 - 0s - 17ms/step - accuracy: 1.0000 - loss: 0.0692\n",
      "Epoch 92/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.0662\n",
      "Epoch 93/100\n",
      "1/1 - 0s - 19ms/step - accuracy: 1.0000 - loss: 0.0633\n",
      "Epoch 94/100\n",
      "1/1 - 0s - 15ms/step - accuracy: 1.0000 - loss: 0.0607\n",
      "Epoch 95/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.0583\n",
      "Epoch 96/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.0560\n",
      "Epoch 97/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.0538\n",
      "Epoch 98/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.0518\n",
      "Epoch 99/100\n",
      "1/1 - 0s - 18ms/step - accuracy: 1.0000 - loss: 0.0499\n",
      "Epoch 100/100\n",
      "1/1 - 0s - 16ms/step - accuracy: 1.0000 - loss: 0.0481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2169b811110>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text generation function\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list, verbose=0), axis=-1)\n",
    "        output_word"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
